# -*- coding: utf-8 -*-
"""detect_scale_difference.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PsvQ1UJi5tvAsjlL8dyVvtK2G_4pxWwR
"""

import subprocess
subprocess.run(["pip", "install", "catboost"])

import pandas as pd
import numpy as np
from google.colab import drive
drive.mount('/content/drive')
import sys
sys.path.append('/content/drive/MyDrive/Colab Notebooks')
# Path to your Python file in Google Drive
file_path = '/content/drive/MyDrive/Colab Notebooks/determine_threshold.py'

# Open the file and read its content
with open(file_path, 'r') as file:
    lines = file.readlines()

# Remove lines containing shell commands (like !jupyter or !pip)
lines = [line for line in lines if not line.startswith('!')]

# Write the cleaned content back to the file
with open(file_path, 'w') as file:
    file.writelines(lines)

print("Removed shell commands from the .py file.")


from determine_threshold import determine_threshold  # Import the function from another file

# Function to detect scale differences dynamically based on the model's sensitivity
def detect_scale_difference(df, model, custom_thresholds=None):
    """
    Detects whether features in a dataset have significantly different scales,
    dynamically adjusting the threshold based on the model used.

    Parameters:
    df (pd.DataFrame): The input dataframe containing features.
    model: The machine learning model being used (e.g., KNeighborsClassifier).
    custom_thresholds (dict): Optional dictionary of custom thresholds.

    Returns:
    dict: Dictionary showing whether each feature has significantly different scale compared to others.
    """

    # Get the dynamic threshold and selected metric based on the model
    selected_metric, threshold = determine_threshold(model, df, custom_thresholds)

    results = {}

    # Get the range (max - min) and standard deviation for each feature
    feature_ranges = df.max() - df.min()
    feature_std = df.std()

    # Calculate the ratio of the largest feature range to the smallest feature range
    min_range = feature_ranges.min()
    min_std = feature_std.min()

    # Iterate over each feature to calculate scale differences
    for col in df.columns:
        if selected_metric == "Variance Ratio":
            # Calculate variance for each feature
            feature_variance = df.var()
            min_variance = feature_variance.min()
            variance_ratio = feature_variance[col] / min_variance
            if variance_ratio > (1 + threshold):
                results[col] = "Different scale detected,standardization recommended"
            else:
                results[col] = "No significant scale difference"

        elif selected_metric == "IQR":
            # Calculate IQR for each feature
            iqr_values = df.apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))
            min_iqr = iqr_values.min()
            iqr_ratio = iqr_values[col] / min_iqr
            if iqr_ratio > (1 + threshold):
                results[col] = "Different scale detected,standardization recommended"
            else:
                results[col] = "No significant scale difference"

        elif selected_metric == "Feature Range":
            # Use the original range calculation
            range_ratio = feature_ranges[col] / min_range
            std_ratio = feature_std[col] / min_std
            if range_ratio > (1 + threshold) or std_ratio > (1 + threshold):
                results[col] = "Different scale detected, standardization recommended"
            else:
                results[col] = "No significant scale difference (range)"

    return results